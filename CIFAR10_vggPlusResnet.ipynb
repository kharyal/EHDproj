{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_VGGNET.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kharyal/EHDproj/blob/master/CIFAR10_vggPlusResnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDS-3UAaZTRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTuMTHuPZiZe",
        "colab_type": "code",
        "outputId": "55cbfe4d-68cc-4a9e-fccd-db2bc7026aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size=64\n",
        "mean = [0.4913997551666284, 0.48215855929893703, 0.4465309133731618]\n",
        "std = [0.24703225141799082, 0.24348516474564, 0.26158783926049628]\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean,std)])\n",
        "trainset=dsets.CIFAR10(root='./data',train=True,\n",
        "                       transform=transform,\n",
        "                       download=True)\n",
        "testset=dsets.CIFAR10(root='./data',\n",
        "                      train=False,\n",
        "                     transform=transform)\n",
        "train_batch=torch.utils.data.DataLoader(dataset=trainset,\n",
        "                                       batch_size=batch_size,\n",
        "                                       shuffle=True,\n",
        "                                       num_workers=2)\n",
        "test_batch=torch.utils.data.DataLoader(dataset=testset,\n",
        "                                      batch_size=batch_size,\n",
        "                                      shuffle=False,\n",
        "                                      num_workers=2)\n",
        "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JGqbor26DEc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "c73ef019-68df-405b-9460-09f57a4d4837"
      },
      "source": [
        "print(trainset.data.shape) # 50,000 images of 32*32*3 dimensions\n",
        "plt.imshow(trainset.data[129])"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0c90088400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY4F-XWfdL5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(net,self).__init__()\n",
        "#     self.pad1=nn.ZeroPad2d()\n",
        "    self.conv1=nn.Conv2d(3,16,3,stride=1,padding=1)\n",
        "    self.conv2=nn.Conv2d(16,16,3,stride=1,padding=1)\n",
        "    self.pool1=nn.MaxPool2d(2,2)\n",
        "    self.conv3=nn.Conv2d(16,32,3,stride=1,padding=1)\n",
        "    self.conv4=nn.Conv2d(32,32,3,stride=1,padding=1)    \n",
        "    self.pool2=nn.MaxPool2d(2,2)\n",
        "    self.conv5=nn.Conv2d(32,64,3,stride=1,padding=1)    \n",
        "    self.conv6=nn.Conv2d(64,64,3,stride=1,padding=1)\n",
        "    self.pool3=nn.MaxPool2d(2,2)\n",
        "    self.conv7=nn.Conv2d(64,128,3,stride=1,padding=1)    \n",
        "    self.conv8=nn.Conv2d(128,128,3,stride=1,padding=1)\n",
        "    self.conv9=nn.Conv2d(128,256,3,stride=1,padding=1)    \n",
        "    self.pool4=nn.MaxPool2d(2,2)\n",
        "    self.conv10=nn.Conv2d(256,256,3,stride=1,padding=1)\n",
        "    self.conv11=nn.Conv2d(256,256,3,stride=1,padding=1)\n",
        "    self.conv12=nn.Conv2d(256,256,3,stride=1,padding=1)\n",
        "    self.conv13=nn.Conv2d(256,256,3,stride=1,padding=1)\n",
        "    self.conv14=nn.Conv2d(256,256,3,stride=1,padding=1)\n",
        "    self.conv15=nn.Conv2d(256,256,3,stride=1,padding=1)\n",
        "    self.conv16=nn.Conv2d(256,256,3,stride=1,padding=1)\n",
        "    self.fc1=nn.Linear(1024,1024)\n",
        "    self.fc2=nn.Linear(1024,1024)\n",
        "    self.fc3=nn.Linear(1024,10)\n",
        "    \n",
        "  \n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.conv1(x))\n",
        "    x=F.relu(self.conv2(x))\n",
        "    x=self.pool1(x)\n",
        "    x=F.relu(self.conv3(x))\n",
        "    x=F.relu(self.conv4(x))\n",
        "    x=self.pool2(x)\n",
        "    x=F.relu(self.conv5(x))\n",
        "    x=F.relu(self.conv6(x))\n",
        "    x=self.pool3(x)\n",
        "    x=F.relu(self.conv7(x))\n",
        "    x=F.relu(self.conv8(x))\n",
        "    x=F.relu(self.conv9(x))\n",
        "    x=self.pool4(x)\n",
        "    x1=F.relu(self.conv10(x))\n",
        "    x1=x+F.relu(self.conv11(x1))\n",
        "    x2=F.relu(self.conv12(x1))\n",
        "    x2=x1+F.relu(self.conv13(x2))\n",
        "    x3=F.relu(self.conv14(x2))\n",
        "    x3=x2+F.relu(self.conv15(x3))\n",
        "    x=F.relu(self.conv16(x3))\n",
        "    x=x.view(-1,x.size(1) * x.size(2) * x.size(3))\n",
        "#     print(x.shape)\n",
        "    x=F.relu(self.fc1(x))\n",
        "    x=F.relu(self.fc2(x))\n",
        "    x=self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MRGsWr4OOLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "network=net()\n",
        "if torch.cuda.is_available():\n",
        "  network.cuda()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(network.parameters(), lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMZGFUJFOnda",
        "colab_type": "code",
        "outputId": "f57a2089-420b-4ea8-a430-ede2988f139a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2331
        }
      },
      "source": [
        "for epoch in range(15):\n",
        "  lossTotal=0\n",
        "  for i, (images, labels) in enumerate(train_batch):\n",
        "    images=Variable(images).cuda()\n",
        "    labels=Variable(labels).cuda()\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    op=network(images)\n",
        "    loss=loss_function(op,labels)\n",
        "    loss.backward()\n",
        "    lossTotal=lossTotal+loss.item()\n",
        "    optimizer.step()\n",
        "    if i%100 ==0:\n",
        "      print(\"local loss: \",loss.item())\n",
        "  print(\"######## end of EPOCH: \",epoch+1,\" LOSS: \",lossTotal,\" ########\")"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "local loss:  2.3024864196777344\n",
            "local loss:  2.2386059761047363\n",
            "local loss:  1.9003804922103882\n",
            "local loss:  1.8787579536437988\n",
            "local loss:  1.8701976537704468\n",
            "local loss:  2.0208847522735596\n",
            "local loss:  1.8484792709350586\n",
            "local loss:  1.74893057346344\n",
            "######## end of EPOCH:  1  LOSS:  1549.4711158275604  ########\n",
            "local loss:  2.006174087524414\n",
            "local loss:  1.8991669416427612\n",
            "local loss:  1.802783727645874\n",
            "local loss:  1.8323256969451904\n",
            "local loss:  1.850560188293457\n",
            "local loss:  1.6103293895721436\n",
            "local loss:  1.6954292058944702\n",
            "local loss:  1.7262121438980103\n",
            "######## end of EPOCH:  2  LOSS:  1357.3904691934586  ########\n",
            "local loss:  1.5127966403961182\n",
            "local loss:  1.568825364112854\n",
            "local loss:  1.5436170101165771\n",
            "local loss:  1.4644930362701416\n",
            "local loss:  1.6651376485824585\n",
            "local loss:  1.473800778388977\n",
            "local loss:  1.511129379272461\n",
            "local loss:  1.5921701192855835\n",
            "######## end of EPOCH:  3  LOSS:  1225.8101818561554  ########\n",
            "local loss:  1.389676570892334\n",
            "local loss:  1.5357255935668945\n",
            "local loss:  1.3190910816192627\n",
            "local loss:  1.4693886041641235\n",
            "local loss:  1.4756056070327759\n",
            "local loss:  1.6598137617111206\n",
            "local loss:  1.5614848136901855\n",
            "local loss:  1.6230794191360474\n",
            "######## end of EPOCH:  4  LOSS:  1119.4919538497925  ########\n",
            "local loss:  1.3997021913528442\n",
            "local loss:  1.2389044761657715\n",
            "local loss:  1.3104406595230103\n",
            "local loss:  1.3848422765731812\n",
            "local loss:  1.3859593868255615\n",
            "local loss:  1.2200826406478882\n",
            "local loss:  1.1174226999282837\n",
            "local loss:  1.2515963315963745\n",
            "######## end of EPOCH:  5  LOSS:  1022.9102956652641  ########\n",
            "local loss:  1.2419607639312744\n",
            "local loss:  0.8899742960929871\n",
            "local loss:  1.1518040895462036\n",
            "local loss:  1.3353002071380615\n",
            "local loss:  1.1728657484054565\n",
            "local loss:  1.1595712900161743\n",
            "local loss:  1.37827467918396\n",
            "local loss:  1.0908173322677612\n",
            "######## end of EPOCH:  6  LOSS:  941.1856819391251  ########\n",
            "local loss:  0.996513307094574\n",
            "local loss:  1.2004839181900024\n",
            "local loss:  1.0267343521118164\n",
            "local loss:  1.0674232244491577\n",
            "local loss:  1.184239387512207\n",
            "local loss:  1.2711410522460938\n",
            "local loss:  0.8363968133926392\n",
            "local loss:  1.1700854301452637\n",
            "######## end of EPOCH:  7  LOSS:  882.5578079819679  ########\n",
            "local loss:  1.2481787204742432\n",
            "local loss:  1.0280282497406006\n",
            "local loss:  1.2462146282196045\n",
            "local loss:  1.3011536598205566\n",
            "local loss:  0.9374832510948181\n",
            "local loss:  0.9855907559394836\n",
            "local loss:  1.0103946924209595\n",
            "local loss:  1.0131593942642212\n",
            "######## end of EPOCH:  8  LOSS:  833.6560372710228  ########\n",
            "local loss:  0.8469444513320923\n",
            "local loss:  1.0111491680145264\n",
            "local loss:  0.7760747671127319\n",
            "local loss:  1.190737247467041\n",
            "local loss:  0.8641371130943298\n",
            "local loss:  1.0612483024597168\n",
            "local loss:  0.9550545811653137\n",
            "local loss:  0.9203779697418213\n",
            "######## end of EPOCH:  9  LOSS:  789.8412145972252  ########\n",
            "local loss:  0.9367071390151978\n",
            "local loss:  1.2159245014190674\n",
            "local loss:  1.3182870149612427\n",
            "local loss:  0.900155782699585\n",
            "local loss:  1.0589679479599\n",
            "local loss:  0.9656976461410522\n",
            "local loss:  1.1504353284835815\n",
            "local loss:  1.0452213287353516\n",
            "######## end of EPOCH:  10  LOSS:  753.9988934993744  ########\n",
            "local loss:  0.9043351411819458\n",
            "local loss:  0.8793802261352539\n",
            "local loss:  0.8303248286247253\n",
            "local loss:  1.0462737083435059\n",
            "local loss:  0.9313296675682068\n",
            "local loss:  0.8780872821807861\n",
            "local loss:  1.1503304243087769\n",
            "local loss:  0.6069295406341553\n",
            "######## end of EPOCH:  11  LOSS:  718.3039159178734  ########\n",
            "local loss:  0.9764723777770996\n",
            "local loss:  0.7726818323135376\n",
            "local loss:  0.6428332328796387\n",
            "local loss:  1.0204838514328003\n",
            "local loss:  1.1935029029846191\n",
            "local loss:  0.9043205380439758\n",
            "local loss:  0.8849086761474609\n",
            "local loss:  0.7272481918334961\n",
            "######## end of EPOCH:  12  LOSS:  685.0209152400494  ########\n",
            "local loss:  0.9268840551376343\n",
            "local loss:  0.7308100461959839\n",
            "local loss:  0.7949928045272827\n",
            "local loss:  1.2788640260696411\n",
            "local loss:  0.8502367734909058\n",
            "local loss:  0.7261450886726379\n",
            "local loss:  0.7473739981651306\n",
            "local loss:  0.8865581154823303\n",
            "######## end of EPOCH:  13  LOSS:  652.3361003100872  ########\n",
            "local loss:  0.7427256107330322\n",
            "local loss:  0.6769999861717224\n",
            "local loss:  0.7714396119117737\n",
            "local loss:  0.7979755401611328\n",
            "local loss:  0.6384626626968384\n",
            "local loss:  0.8081921339035034\n",
            "local loss:  0.9981722831726074\n",
            "local loss:  0.8647530674934387\n",
            "######## end of EPOCH:  14  LOSS:  620.3113290071487  ########\n",
            "local loss:  0.7353870868682861\n",
            "local loss:  0.7829654216766357\n",
            "local loss:  0.7781738042831421\n",
            "local loss:  0.6456670165061951\n",
            "local loss:  0.8389430046081543\n",
            "local loss:  0.8746762275695801\n",
            "local loss:  0.589185357093811\n",
            "local loss:  0.7354975938796997\n",
            "######## end of EPOCH:  15  LOSS:  591.517118871212  ########\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClG6iGq6YfOQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a6bf4a6-9bd8-473e-d162-8cfdf1a56688"
      },
      "source": [
        "correct=0\n",
        "total=0\n",
        "for images,labels in test_batch:\n",
        "  images=Variable(images).cuda()\n",
        "  labels=Variable(labels).cuda()\n",
        "  \n",
        "  output = network(images)\n",
        "  _, predicted = torch.max(output,1)\n",
        "  correct += (predicted == labels).sum()\n",
        "  total += labels.size(0)\n",
        "print(\"accuracy: \",(100*correct)/(total+1))"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:  tensor(68, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}